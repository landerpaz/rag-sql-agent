{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d69fb-07a3-4199-a126-0e6f7964b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyprojroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca9de52-1b74-4619-89a2-ecb3a569f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ea459-ee53-4482-8be2-56fe6e91f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55632968-88fa-4189-815a-9403d2186cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprojroot import here\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85180d4f-4931-4a6d-8364-8cff4ff28189",
   "metadata": {},
   "source": [
    "<b>Create LLM client</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1fba6-b9f5-4eb1-adfe-4287d98dab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce5256c-3da3-4ac8-9a2c-e5b192cf84b5",
   "metadata": {},
   "source": [
    "<b>Create vector DB client</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee31945-e1d6-41fe-b285-e1bd0f035248",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=str(here(\"/Users/ashokarulsamy/Python Learning/itam/data/chroma_db/chroma_itam_ada\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc6e4ef-894d-433e-8ece-af36ccaf7415",
   "metadata": {},
   "source": [
    "<b>Create collection in vector DB</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19200669-c640-4572-942a-e785f0dc9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Already executed\n",
    "collection = chroma_client.create_collection(name=\"itam_hw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450cfa7-e2a7-4b9d-add6-af8de4a94ab5",
   "metadata": {},
   "source": [
    "<b>Load data from csv file into data frame</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e01b2-3ef5-4f65-a5d3-a9c556ae1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = here(\"/Users/ashokarulsamy/Python Learning/itam/data/itam_files/itam_hw.csv\")\n",
    "df = pd.read_csv(file_dir, nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ee7cb-216c-4c28-85f3-79e79a406f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaff78e-7915-433e-9d1c-3ae87b5e4a6a",
   "metadata": {},
   "source": [
    "<b>Create chunk and generate vector represenattion for chunk using embedding model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe17516-de02-4729-90f9-68dbe6998d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Already executed\n",
    "docs = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "embeddings = []\n",
    "for index, row in df.iterrows():\n",
    "    output_str = \"\"\n",
    "    # Treat each row as a separate chunk\n",
    "    for col in df.columns:\n",
    "        output_str += f\"{col}: {row[col]},\\n\"\n",
    "    response = client.embeddings.create(input = [output_str], model=\"text-embedding-ada-002\").data[0].embedding\n",
    "    embeddings.append(response)\n",
    "    docs.append(output_str)\n",
    "    metadatas.append({\"source\": \"itam_hw\"})\n",
    "    ids.append(f\"id{index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4530ae-e49b-4427-a1b9-ce035ae1e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a018dc26-f477-4872-b4f7-56f7d9776df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metadatas)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b5f75-3f54-400b-987f-aad650a9967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36926924-1871-4b62-9e5c-ea05d7db29d7",
   "metadata": {},
   "source": [
    "<b>Vector embedding - Load vector represenation in vector DB</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f173b12-674d-4bde-a4f9-0b06e6a82177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Already executed\n",
    "collection.add(\n",
    "    documents=docs,\n",
    "    metadatas=metadatas,\n",
    "    embeddings=embeddings,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00818ab-0daf-41dc-819c-cc63c5a1bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of vectors in vectordb:\", collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7882dcec-b35e-46ad-9118-a49e7143ed18",
   "metadata": {},
   "source": [
    "<b>Vector embedding for user query</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082ae2d-40df-4f51-9a26-6f09b041844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"I'm Ashok Arulsamy, list out assets assigned to me\"\n",
    "#user_query = \"List of retired assets\"\n",
    "#user_query = \"list of assets for which warrenty expires in the year 2025\"\n",
    "#user_query = \"How many hardware assets are there\" # try agent as semantic search will return huge volume of data\n",
    "user_query_embeddings = client.embeddings.create(input = [user_query], model=\"text-embedding-ada-002\").data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ecca91-0252-43f2-86ef-7e99dc13f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c06bb-8fa8-4da9-b81c-994e85f189e4",
   "metadata": {},
   "source": [
    "<b>Create vector DB instance</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54305e-7cd3-438f-99e2-95a0aeaa23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = chroma_client.get_collection(name=\"itam_hw\")\n",
    "vectordb.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e7e23-19c4-48d6-b062-857ec88ebeaa",
   "metadata": {},
   "source": [
    "<b>Semantic search for user query against vector DB</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5f2fe-1982-4c38-81ed-2e0b23197078",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_context = vectordb.query(\n",
    "    query_embeddings = user_query_embeddings,\n",
    "    n_results=5 #top_k\n",
    ")\n",
    "\n",
    "retrieved_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a7d90-6670-4feb-bef6-20140141ac16",
   "metadata": {},
   "source": [
    "<b>Generate user friendly message using LLM</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bd37d-93ba-4a27-a4d4-c64e1903237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant that provides detailed answers.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"User's question: {user_query}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Retrieved content: {retrieved_context}\"}\n",
    "    ],\n",
    "    temperature=0.0,  # Controls creativity (0.0 = deterministic, 1.0 = creative)\n",
    "    max_tokens=1000,   # Adjust as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46a42d-34c5-46e9-b17a-03805a2a65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generated Answer:\")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
